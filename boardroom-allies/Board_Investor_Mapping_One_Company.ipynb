{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Custom String Field for Salesforce Instance\n",
    "## Example call for one input company\n",
    "\n",
    "**Last Updated: January 1, 2021** | Created by <a href='https://www.linkedin.com/in/sophiaskowronski/'>Sophia Skowronski</a> | Data sourced from <a href='http://www.crunchbase.com/'>Crunchbase</a> via Enterprise License Agreement\n",
    "\n",
    "Given an input company, generate dataframe of customized strings of affiliated individuals and companies:\n",
    "\n",
    "- Current Board Members\n",
    "- Former Board Members\n",
    "- Current Board Advisors/Observers\n",
    "- Former Board Advisors/Observers\n",
    "- All Investors\n",
    "- All Investors, grouped by financing type\n",
    "\n",
    "#### Overview\n",
    "1. Use `autocompletes` function to find the input company's uuid.\n",
    "2. Use `makequery_board_affiliations` and `go_past_1000` functions to pull all current and former board affiliations of the input company.\n",
    "3. Use `primary_info`function to obtain primary job title, primary organization, and LinkedIn of each individual.\n",
    "4. Transform affiliations into dictionaries of concatenated strings. Save to CSV file.\n",
    "5. Use `makequery_investors` and `go_past_1000` functions to pull all investors of the input company. \n",
    "6. Transform investment information into dictionaries of concatenated strings. Update CSV file & print out results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import requests\n",
    "import json\n",
    "from json import JSONDecodeError\n",
    "import pandas as pd\n",
    "from pandas import json_normalize \n",
    "\n",
    "# P1s Crunchbase API user key\n",
    "from user_key import userkey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_count(query, query_type): \n",
    "    '''\n",
    "    Return the total number of results of a query, and then, deserialize the results to a Python dictionary object.\n",
    "    ''' \n",
    "    # POST method with API URL, query_type as a parameter, and passing query as json.\n",
    "    r = requests.post('https://api.crunchbase.com/api/v4/searches/' + query_type, params=userkey, json=query)\n",
    "    # Return total number of results of query\n",
    "    return json.loads(r.text)['count']\n",
    "\n",
    "def url_extraction(query, query_type):    \n",
    "    '''\n",
    "    Return the results for a query, and then, deserialize to a Python dictionary object.\n",
    "    ''' \n",
    "    # Create global raw variable. This ensures that it can be updated if the API call needs to loop.\n",
    "    global raw   \n",
    "    # POST method with API URL, query_type as a parameter, and passing query as json.\n",
    "    r = requests.post('https://api.crunchbase.com/api/v4/searches/' + query_type, params=userkey, json=query)\n",
    "    # Return results of query\n",
    "    result = json.loads(r.text)\n",
    "    # Normalize semi-structured JSON data into a flat table, forcing it to fit into a relational data structure.\n",
    "    normalized_raw = json_normalize(result['entities'])\n",
    "    # Append normalized entity results to global raw variable\n",
    "    raw = raw.append(normalized_raw, ignore_index=True)\n",
    "\n",
    "def autocompletes(query, collection_ids_list=None, limit=None):\n",
    "    '''\n",
    "    Suggests matching Identifier entities based on the query and entity_def_ids provided.\n",
    "    \n",
    "    QUERY\n",
    "    Value to perform the autocomplete search with.\n",
    "    \n",
    "    COLLECTION_IDS_LIST\n",
    "    A comma separated list of collection ids to search against. \n",
    "    Leaving this blank means it will search across all identifiers. \n",
    "    Entity defs can be constrained to specific facets by providing them as facet collections. \n",
    "    Relationship collections will resolve to their underlying entity def.\n",
    "    Collection ids are: organizations, people, funding_rounds, acquisitions, investments,\n",
    "    events, press_references, funds, event_appearances, ipos, ownerships, categories, \n",
    "    category_groups, locations, jobs\n",
    "    \n",
    "    LIMIT\n",
    "    Number of results to retrieve; default = 10, max = 25\n",
    "    '''\n",
    "    # Create parameter dictionary to pass into POST method\n",
    "    params = {**userkey, 'query': query}\n",
    "    # Add input collection ids to parameters dictionary\n",
    "    if collection_ids_list and type(collection_ids_list) == list:\n",
    "        params.update({'collection_ids': collection_ids_list})\n",
    "    # Add input limit to parameters dictionary\n",
    "    if limit and type(limit) == int:\n",
    "        params.update({'limit': limit}) \n",
    "    # POST method with API URL, query_type as a parameter, and passing query as json.\n",
    "    r = requests.get('https://api.crunchbase.com/api/v4/autocompletes', params=params)\n",
    "    # Return results of query\n",
    "    result = json.loads(r.text)\n",
    "    # Normalize semi-structured JSON data into a flat table, forcing it to fit into a relational data structure.\n",
    "    normalized_result = json_normalize(result['entities'])\n",
    "    # Return results of autocompletes query as pandas dataframe\n",
    "    return pd.DataFrame.from_dict(normalized_result)\n",
    "\n",
    "def makequery_board_affiliations(uuid_list, limit=1000):\n",
    "    '''\n",
    "    Job Search: Board Affiliations\n",
    "    - Organization includes list of `uuid` values\n",
    "    - Excludes `employee` and `executive` level jobs\n",
    "    '''\n",
    "    query = {\n",
    "        'field_ids': [ # ADD FIELD IDS HERE\n",
    "            'entity_def_id',\n",
    "            'identifier',\n",
    "            'job_type',\n",
    "            'name',\n",
    "            'organization_identifier',\n",
    "            'person_identifier',\n",
    "            'short_description',\n",
    "            'is_current',\n",
    "            'started_on',\n",
    "            'ended_on',\n",
    "            'title',\n",
    "            'updated_at',\n",
    "            'uuid'],\n",
    "        'limit': limit, # INPUT LIMIT\n",
    "        'query': [ # FILTERING CONDITIONS HERE\n",
    "            {\n",
    "                'type': 'predicate',\n",
    "                'field_id': 'organization_identifier',\n",
    "                'operator_id': 'includes',\n",
    "                'values': uuid_list # INPUT UUID_LIST\n",
    "            },\n",
    "            {\n",
    "                'type': 'predicate',\n",
    "                'field_id': 'job_type',\n",
    "                'operator_id': 'not_includes',\n",
    "                'values': ['employee', 'executive']\n",
    "            }]\n",
    "    }\n",
    "    return query\n",
    "\n",
    "def primary_info(person_id, field_ids_list=['primary_job_title','primary_organization','linkedin'], card_ids_list=None):\n",
    "    '''\n",
    "    PERSON_ID\n",
    "    UUID or permalink of desired entity\n",
    "    \n",
    "    FIELD_IDS\n",
    "    Fields to include on the resulting entity - \n",
    "    either an array of field_id strings in JSON \n",
    "    or a comma-separated list encoded as string\n",
    "    \n",
    "    CARD_IDS\n",
    "    Cards to include on the resulting entity - \n",
    "    array of card_id strings in JSON encoded as string\\ \n",
    "    Card Ids for Person: [degrees, event_appearances, fields, \n",
    "    founded_organizations, jobs, participated_funding_rounds, \n",
    "    participated_funds, participated_investments, partner_funding_rounds, \n",
    "    partner_investments, press_references, primary_job, primary_organization]\n",
    "    '''\n",
    "    # Create parameter dictionary to pass into POST method\n",
    "    params = {**userkey}\n",
    "    # Add input field ids to parameters dictionary\n",
    "    if field_ids_list and type(field_ids_list) == list:\n",
    "        params.update({'field_ids':','.join(field_ids_list)})\n",
    "    # Add input cards ids to parameters dictionary\n",
    "    if card_ids_list and type(card_ids_list) == list:\n",
    "        params.update({'card_ids':','.join(card_ids_list)})\n",
    "    # POST method with API URL, query_type as a parameter, and passing query as json.    \n",
    "    r = requests.get('https://api.crunchbase.com/api/v4/entities/people/' + person_id, params=params)\n",
    "    # Return results of query\n",
    "    result = json.loads(r.text)\n",
    "    # Pull uuid of searched individual\n",
    "    uuid = result['properties']['identifier']['uuid']\n",
    "    name = result['properties']['identifier']['value']\n",
    "    # Pull LinkedIn URL from json results (if it exists)\n",
    "    try:\n",
    "        linkedin = result['properties']['linkedin']['value']\n",
    "    except KeyError:\n",
    "        linkedin = 'NA'\n",
    "    # Pull primary job title from json results (if it exists)\n",
    "    try:\n",
    "        title = result['properties']['primary_job_title']\n",
    "    except KeyError:\n",
    "        title = 'NA' \n",
    "    # Pull primary organization from json results (if it exists)\n",
    "    try:\n",
    "        org = result['properties']['primary_organization']['value']\n",
    "    except KeyError:\n",
    "        org = 'NA'   \n",
    "    # Pull primary organization uuid from json results (if it exists)    \n",
    "    try:\n",
    "        org_uuid = result['properties']['primary_organization']['uuid']\n",
    "    except KeyError:\n",
    "        org_uuid = 'NA'\n",
    "    return {uuid:name}, {uuid:title}, {uuid:org}, {uuid:org_uuid}, {uuid:linkedin}\n",
    "\n",
    "def makequery_investors(uuid, limit=1000):\n",
    "    '''\n",
    "    '''\n",
    "    query = {\n",
    "        'field_ids': [\n",
    "            'name',\n",
    "            'investor_identifier',\n",
    "            'organization_identifier',\n",
    "            'partner_identifiers'\n",
    "        ],\n",
    "        'limit': limit, # INPUT LIMIT\n",
    "        'query': [ # FILTERING CONDITIONS HERE\n",
    "            {\n",
    "                'type': 'predicate',\n",
    "                'field_id': 'organization_identifier',\n",
    "                'operator_id': 'includes',\n",
    "                'values': uuid\n",
    "            }]\n",
    "    }\n",
    "    return query\n",
    "\n",
    "def go_past_1000(query, query_type, comp_count):\n",
    "    global raw\n",
    "    data_acq = 0\n",
    "    while data_acq < comp_count:\n",
    "        # Query loop\n",
    "        if data_acq != 0: \n",
    "            # Selects the most recently added result\n",
    "            last_uuid = raw.uuid[len(raw.uuid)-1] \n",
    "            # Saves most recent uuid query so POST request starts after this one\n",
    "            query['after_id'] = last_uuid \n",
    "            # Extracts data \n",
    "            url_extraction(query, query_type) \n",
    "            # Updates data_acq variable\n",
    "            data_acq = len(raw.uuid)\n",
    "        else:\n",
    "            # Removes after_id in case its there before the query starts.\n",
    "            if 'after_id' in query: \n",
    "                query = query.pop('after_id')\n",
    "                # Extracts data \n",
    "                url_extraction(query, query_type)\n",
    "                # Updates data_acq variable\n",
    "                data_acq = len(raw.uuid)\n",
    "            # Starting query loop\n",
    "            else:\n",
    "                # Extracts data \n",
    "                url_extraction(query, query_type)\n",
    "                # Updates data_acq variable\n",
    "                data_acq = len(raw.uuid)\n",
    "\n",
    "def grab_uuid(x):\n",
    "    try:\n",
    "        return x[0]['uuid']\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "def grab_name(x):\n",
    "    try:\n",
    "        return x[0]['value']\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "# Column/field mapper dictionnairies\n",
    "column_mapper = {'properties.organization_identifier.value':'company',\n",
    "                 'properties.person_identifier.value':'person', \n",
    "                 'properties.person_identifier.uuid':'person_uuid',\n",
    "                 'properties.title':'title', \n",
    "                 'properties.job_type':'job_type', \n",
    "                 'properties.started_on.value':'started_on',\n",
    "                 'properties.ended_on.value':'ended_on',\n",
    "                 'properties.is_current':'is_current',\n",
    "                 'properties.updated_at':'record_last_updated',\n",
    "                 'properties.investor_identifier.uuid':'investor_uuid',\n",
    "                 'properties.investor_identifier.value':'investor_name'}\n",
    "order = ['Grant','Pre Seed Round','Seed Round','Series A','Series B','Series C',\n",
    "         'Series D','Series E','Series F','Series G','Series H','Series I',\n",
    "         'Series J','Series K','Secondary Market','Private Equity Round',\n",
    "         'Debt Financing','Angel Round','Funding Round','Venture Round',\n",
    "         'Corporate Round','Non Equity Assistance', 'Convertible Note', 'Post-IPO Equity','']\n",
    "shorthand = ['Grant','Pre Seed', 'Seed','A','B','C','D','E','F','G','H','I','J','K',\n",
    "             'Secondary','Private Eq', 'Debt', 'Angel Rnd', 'Funding Rnd', \n",
    "             'Venture Rnd', 'Corporate Rnd', 'Non Equity Assist', 'Convert Note',\n",
    "             'Post-IPO Equity','']\n",
    "shorthand_map = dict(zip(order,shorthand))\n",
    "order = {key: i for i, key in enumerate(order)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Searching for SALESFORCE\n",
      "**************************************************\n",
      "Found SALESFORCE !!!!!!!\n",
      "DESCRIPTION: Salesforce is a global cloud computing company that develops CRM solutions and provides business software on a subscription basis.\n",
      "\n",
      "Total records found: 30\n",
      "Total unique records found: 30\n",
      "\n",
      "Count of API calls, number of unique individuals found in query:\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 \n",
      "\n",
      "9 out of 30 records are missing either a primary job title, primary organization, or LinkedIn url.\n",
      "\n",
      "**************************************************\n",
      "Results for SALESFORCE\n",
      "**************************************************\n",
      "COMPANY:\n",
      "Salesforce\n",
      "\n",
      "\n",
      "CURRENT BOARD MEMBERS:\n",
      " Alan Hassenfeld (Salesforce); Colin Powell (Kleiner Perkins); Craig Conway (Salesforce); John Roos (Geodesic Capital); Larry Tomlinson (Salesforce); Magdalena Yesil (Broadway Angels); Marc Benioff (Salesforce); Maynard Webb (Webb Investment Network); Nathan Totten; Neelie Kroes (StartupDelta); Robin Washington; Sandy Robertson (Francisco Partners); Sanford Robertson (Salesforce); Susan Wojcicki (YouTube)\n",
      "\n",
      "\n",
      "FORMER BOARD MEMBERS:\n",
      " Allen Miner (SunBridge); Craig Ramsey (Vlocity); Frank Veenendaal (NewVoiceMedia); Ian Sigalow (Greycroft); Paul Hsiao (Canvas Ventures); Paul Madera (Meritech Capital Partners); Scott Sandell (New Enterprise Associates); Tan Hooi Ling (Grab); Thomas Lah (TSIA); Tigh Loughhead\n",
      "\n",
      "\n",
      "CURRENT BOARD ADVISORS/OBSERVERS:\n",
      " Andrea Gaspar; Eiji Uda; Julie Hansen; Sandi Mays (Zayo)\n",
      "\n",
      "\n",
      "FORMER BOARD ADVISORS/OBSERVERS:\n",
      " Geoffrey Moore (Wildcat Venture Partners); Yiannis Maos (Birmingham Tech (Birmingham Tech Week))\n",
      "\n",
      "\n",
      "INVESTORS (ALL):\n",
      "Allen Miner; Attractor Investment Management; Credit Suisse First Boston; Dave Moellenhoff; Emergence; Halsey Minor; Igor Sill; John Friedenrich; MF Capital; Magdalena Yesil; Marc Benioff; Meritech Capital Partners; New Enterprise Associates; Parker Harris; Patrick McGovern; Stratton Sclavos; SunBridge; Ted Waitt; WR Hambrecht; William Hambrecht\n",
      "\n",
      "\n",
      "INVESTORS (W/ INFO):\n",
      "Series A (Dave Moellenhoff; Marc Benioff; Parker Harris) | Series B (Dave Moellenhoff; Halsey Minor; Magdalena Yesil; Marc Benioff; Parker Harris) | Series C (Halsey Minor; Igor Sill; John Friedenrich; Marc Benioff; Patrick McGovern; William Hambrecht) | Series D (Allen Miner; Attractor Investment Management; Credit Suisse First Boston; Halsey Minor; MF Capital; Marc Benioff; Meritech Capital Partners; Stratton Sclavos; SunBridge; Ted Waitt; WR Hambrecht; William Hambrecht) | Venture Round (Emergence; New Enterprise Associates)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "company = 'Salesforce'\n",
    "\n",
    "found = autocompletes(company, ['organizations'], limit=1)\n",
    "uuid = found['identifier.uuid'][0]\n",
    "    \n",
    "print('*'*50)\n",
    "print('Searching for {}'.format(company.upper()))\n",
    "print('*'*50)\n",
    "print('Found {} !!!!!!!\\nDESCRIPTION: {}\\n'.format(found['identifier.value'][0].upper(), found['short_description'][0]))\n",
    "\n",
    "# Make query of current/former board affiliations for companies\n",
    "query = makequery_board_affiliations([uuid])\n",
    "\n",
    "# Global raw variable\n",
    "raw = pd.DataFrame()\n",
    "\n",
    "# Run query w/ API call, which populates dataframe with query results\n",
    "url_extraction(query, 'jobs')\n",
    "\n",
    "# Filter down the query dataframe to usable fields\n",
    "board_affiliations = raw[['properties.organization_identifier.value',  # Company name\n",
    "                          'properties.person_identifier.uuid', # Person UUID\n",
    "                          'properties.person_identifier.value',  # Person name\n",
    "                          'properties.title',  # Job title of board affiliation\n",
    "                          'properties.job_type',  # Crunchbase job_type\n",
    "                          'properties.is_current', # Boolean of whether job is current or not\n",
    "                          'properties.started_on.value', # Job start date\n",
    "                          'properties.ended_on.value', # Job end date\n",
    "                          'properties.updated_at'] # When Crunchbase last updated the record\n",
    "                        ].sort_values(['properties.organization_identifier.value']).reset_index(drop=True) # Sory by company name\n",
    "board_affiliations = board_affiliations.rename(column_mapper, axis=1)\n",
    "\n",
    "# Get UUIDs of people\n",
    "uuid_board_members = list(set(board_affiliations['person_uuid'].to_list()))\n",
    "\n",
    "# Display\n",
    "print('Total records found: {}'.format(board_affiliations.shape[0]))\n",
    "print('Total unique records found: {}\\n'.format(len(uuid_board_members)))\n",
    "    \n",
    "# Start with empty dictionnaries\n",
    "all_names = {}\n",
    "all_titles = {}\n",
    "all_orgs = {}\n",
    "all_orgs_uuid = {}\n",
    "all_linkedin = {}\n",
    "no_primary_info = []\n",
    "\n",
    "# For each API call, update dictionary if it's not empty\n",
    "i = 0\n",
    "print('Count of API calls, number of unique individuals found in query:')\n",
    "while i < len(uuid_board_members):\n",
    "    print(i+1,end=' ')\n",
    "    person = uuid_board_members[i]\n",
    "    try: \n",
    "        # API Call\n",
    "        name, primary_job_title, primary_org, primary_org_uuid, linkedin = primary_info(person)\n",
    "        all_names.update(name)\n",
    "        # Update job title dictionary as long as its not equal to 'NA'\n",
    "        if primary_job_title[person] != 'NA':\n",
    "            all_titles.update(primary_job_title)\n",
    "        # Update organization dictionary as long as its not equal to 'NA'\n",
    "        if primary_org[person] != 'NA':\n",
    "            all_orgs.update(primary_org)\n",
    "        # Update organization dictionary as long as its not equal to 'NA'\n",
    "        if primary_org_uuid[person] != 'NA':\n",
    "            all_orgs_uuid.update(primary_org_uuid)\n",
    "        # Update LinkedIn dictionary as long as its not equal to 'NA'\n",
    "        if linkedin[person] != 'NA':\n",
    "            all_linkedin.update(linkedin)\n",
    "        # If any are equal to 'NA', store in no_primary_info list for safekeeping.\n",
    "        if primary_job_title[person] == 'NA' or primary_org[person] == 'NA' or linkedin[person] == 'NA' or primary_org_uuid[person] =='NA':\n",
    "            no_primary_info.append(person)\n",
    "        # Continue looping\n",
    "        i += 1\n",
    "    except JSONDecodeError:\n",
    "        print('[From Crunchbase: Usage limit exceeded. Pause for 5 seconds and continue.]',end =' ')\n",
    "        time.sleep(5)\n",
    "\n",
    "# Count of how many are missing Title, Organization, or LinkedIn\n",
    "print('\\n\\n{} out of {} records are missing either a primary job title, primary organization, or LinkedIn url.\\n'.format(len(no_primary_info),i))\n",
    "\n",
    "# Add primary title, organization, and LinkedIn to dataframe\n",
    "board_affiliations['person_title'] = board_affiliations['person_uuid'].map(all_titles)\n",
    "board_affiliations['primary_org'] = board_affiliations['person_uuid'].map(all_orgs)\n",
    "board_affiliations['person_linkedin'] = board_affiliations['person_uuid'].map(all_linkedin)\n",
    "\n",
    "# Pull unique list of company names from series\n",
    "company_list = list(set(board_affiliations['company'].to_list()))\n",
    "company_list.sort()\n",
    "\n",
    "# CURRENT BOARD MEMBERS\n",
    "current_board_members = board_affiliations[(board_affiliations['is_current']) & \n",
    "                                           (board_affiliations['job_type']=='board_member')\n",
    "                                          ].sort_values(['person'])\n",
    "# FORMER BOARD MEMBERS\n",
    "former_board_members = board_affiliations[(board_affiliations['is_current']==False) &\n",
    "                                          (board_affiliations['job_type']=='board_member')\n",
    "                                         ].sort_values(['person'])\n",
    "# CURRENT BOARD ADVISORS/OBSERVERS\n",
    "current_board_other = board_affiliations[(board_affiliations['is_current']) &\n",
    "                                         (board_affiliations['job_type']!='board_member')\n",
    "                                        ].sort_values(['person'])\n",
    "# FORMER BOARD ADVISORS/OBSERVERS\n",
    "former_board_other = board_affiliations[(board_affiliations['is_current'] == False) &\n",
    "                                          (board_affiliations['job_type']!='board_member')\n",
    "                                         ].sort_values(['person'])\n",
    "# To iterate through\n",
    "frames = [current_board_members, former_board_members, current_board_other, former_board_other]\n",
    "\n",
    "# For saving to csv\n",
    "all_dict = []\n",
    "for df in frames:\n",
    "    # Fill in affiliation dictionary\n",
    "    people_dict = {}\n",
    "    # For each company\n",
    "    for org in company_list:\n",
    "        # Filter df to unique company affiliations\n",
    "        temp_df = df[df['company']==org]\n",
    "        # Collapse individual names to list\n",
    "        names = temp_df['person'].to_list()\n",
    "        # Collapse individual organizations to list\n",
    "        companies = temp_df['primary_org'].to_list()\n",
    "        # Start with empty string\n",
    "        board_string = ''\n",
    "        # Exclude if there are no individuals affiliated\n",
    "        if names != []:\n",
    "            # Make temp dictionary of name:org\n",
    "            board_info = dict(zip(names, companies))\n",
    "            # Add them to string\n",
    "            for name, company in sorted(board_info.items()):\n",
    "                # If individual does not have a primary organization\n",
    "                if pd.isna(company):\n",
    "                    board_string += name + '; '\n",
    "                # If individual has a primary organziation, place into parentheses\n",
    "                else:\n",
    "                    board_string += name + ' (' + company + '); '\n",
    "            # Remove trailing semicolon and remove extra commas\n",
    "            board_string = board_string[:-2].replace(',', '')\n",
    "        # Add string to main dictionary \n",
    "        people_dict[org] = board_string\n",
    "    all_dict.append(people_dict)\n",
    "    \n",
    "# Save to CSV\n",
    "with open('output/search_example.csv', 'w') as f:\n",
    "    for i,key in enumerate(company_list):\n",
    "        if i == 0:\n",
    "            # Add header\n",
    "            f.write('Company,Current Board Members,Former Board Members,Current Board Advisors/Observers,Former Board Advisors/Observers\\n')\n",
    "            f.write('%s, %s, %s, %s, %s\\n' % (key,all_dict[0][key],all_dict[1][key],all_dict[2][key],all_dict[3][key]))\n",
    "        else:\n",
    "            f.write('%s, %s, %s, %s, %s\\n' % (key,all_dict[0][key],all_dict[1][key],all_dict[2][key],all_dict[3][key]))  \n",
    "\n",
    "# Get all of the investors for P1 companies\n",
    "query = makequery_investors([uuid])\n",
    "\n",
    "# Global raw variable\n",
    "raw = pd.DataFrame() \n",
    "comp_count = url_count(query, 'investments') \n",
    "go_past_1000(query, 'investments', comp_count)\n",
    "\n",
    "# Create dataframe that contains the investor name, org name, and type of investment (for grouping)\n",
    "investors = raw.sort_values('properties.organization_identifier.value')[['properties.investor_identifier.uuid',\n",
    "                                                                            'properties.investor_identifier.value',\n",
    "                                                                            'properties.identifier.value',\n",
    "                                                                            'properties.organization_identifier.value',\n",
    "                                                                           'properties.partner_identifiers']].reset_index(drop=True)\n",
    "investors['properties.investor_identifier.value'] = investors['properties.investor_identifier.value'].str.strip('-')\n",
    "\n",
    "# Extract financing type from title string\n",
    "investors['type'] = investors['properties.identifier.value'].str.partition(' - ')[0].str.partition(' in ')[2]\n",
    "\n",
    "# Map uuids w/ custom dictionnaries to add new dataframe columns\n",
    "investors['partner_uuid'] = investors['properties.partner_identifiers'].apply(grab_uuid)\n",
    "investors['partner_name'] = investors['properties.partner_identifiers'].apply(grab_name)\n",
    "investors = investors.drop(['properties.identifier.value','properties.partner_identifiers'], axis=1)\n",
    "investors = investors.fillna('Not Listed')\n",
    "\n",
    "# Send through column_mapper\n",
    "investors = investors.rename(column_mapper, axis=1)\n",
    "\n",
    "# Remove duplicates\n",
    "investors = pd.DataFrame(investors.groupby(['investor_uuid','investor_name','company','type','partner_uuid','partner_name']).count().reset_index())\n",
    "\n",
    "all_investors = {}\n",
    "for co in investors.company.unique():\n",
    "    investor_str = ''\n",
    "    # Create sub-DF with just the company's investors\n",
    "    co_df = investors[investors['company']==co]\n",
    "    # Turn into list\n",
    "    co_investors = sorted(list(set(co_df['investor_name'].to_list())))\n",
    "    for inv in co_investors:\n",
    "        # Add investor to string\n",
    "        investor_str += inv + '; '\n",
    "    # Remove trailing semicolon\n",
    "    investor_str = investor_str[:-2]\n",
    "    all_investors[co] = investor_str  \n",
    "\n",
    "all_investors_w_info = {}\n",
    "for co in investors.company.unique():\n",
    "    investor_str = ''\n",
    "    # Create sub-DF with just the company's investors\n",
    "    co_df = investors[investors['company']==co]\n",
    "    # Create unique list of investment types\n",
    "    lst = list(set(co_df['type'].to_list()))\n",
    "    lst = sorted(lst, key=lambda d: order[d])\n",
    "    for item in lst:\n",
    "        # Create sub-list of investors with a particular investment type\n",
    "        investor_type_lst = sorted(list(set(co_df['investor_name'][co_df['type']==item].to_list())))\n",
    "        if investor_type_lst != []:\n",
    "            # Add investment type to string\n",
    "            investor_str += item + ' ('\n",
    "            for com in investor_type_lst:\n",
    "                # Add investor to string\n",
    "                investor_str += com + '; '\n",
    "            # Remove trailing semicolon and add end parenthesis\n",
    "            investor_str = investor_str[:-2]\n",
    "            investor_str += ') | '\n",
    "    # Remove trailing characters\n",
    "    investor_str = investor_str[:-3]\n",
    "    all_investors_w_info[co] = investor_str  \n",
    "    \n",
    "# Add new concatenated strings to dataframe\n",
    "mapping = pd.read_csv('output/search_example.csv')\n",
    "mapping['Investors (All)'] = mapping['Company'].map(all_investors)\n",
    "mapping['Investors (w/ Info)'] = mapping['Company'].map(all_investors_w_info)\n",
    "mapping.to_csv('output/search_example.csv', index=False)\n",
    "\n",
    "# Output\n",
    "print('*'*50)\n",
    "print('Results for {}'.format(org.upper()))\n",
    "print('*'*50)\n",
    "for idx,col in enumerate(mapping.columns):\n",
    "    print('{}:\\n{}\\n\\n'.format(col.upper(), mapping.loc[0,col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Relationships w/ turicreate & NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
